<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Lecture 7: Making Machines Learn</title>

		<meta name="description" content="Lesson 6 for SAMS 2013 CMU Class">
		<meta name="author" content="Wolfgang Richter">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="../css/reveal.css">
		<link rel="stylesheet" href="../css/simple.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="../css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="../css/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Cyber Security</h1>
					<h3>Making Machines Learn</h3>
					<p>
                    <a href="mailto:wolf@cs.cmu.edu">Wolfgang Richter</a>
					</p>
                    <p><small>Built with <a href="http://lab.hakim.se/reveal-js/">reveal.js</a></small></p>
				</section>
                <section>
                <h3>Attackers are automated at large scale.</h3>
                <h3 class="fragment">Defenses must also become automated.</h3>
                <h3 class="fragment" style="color:red;">How do you classify good vs bad?</h3>
                </section>
                <section>
                <h2>Why Machine Learning (ML)?</h2>
                <p style="text-align:left;"><a href="http://youtu.be/cdgQpa1pUUE">Self-driving cars</a></p>
                <p style="text-align:left;"><a href="http://www.youtube.com/watch?v=9pmPa_KxsAM&feature=youtu.be&t=2h">Natural language processing</a></p>
                <p style="text-align:left;"><a href="http://www.youtube.com/watch?feature=player_embedded&v=gjIUv84U_E0">Speech analysis</a></p>
                <p style="text-align:left;"><a href="http://stackoverflow.com/questions/9413216/simple-digit-recognition-ocr-in-opencv-python">Optical character recognition</a></p>
                <p style="text-align:left;"><a href="https://en.wikipedia.org/wiki/Bayesian_spam_filtering">Detect spam</a></p>
                <p style="text-align:left;"><a href="http://youtu.be/1GhNXHCQGsM">Computer vision</a></p>
                <p style="text-align:left;">Big data&#8230;</p>
                </section>
                <section>
                <h2 style="color:red;"><strong>Nothing is magical</strong></h2>
                </section>
                <section>
                <h2>Our Job</h2>
                <img src="email.png">
                <p style="text-align:left;"><strong>Two class problem:</strong> spam and not spam.</p>
                </section>
                <section>
                <h2>General ML Steps</h2>
                <p style="text-align:left;"><span style="font-size:200%;">1</span>Extract features</p>
                <p style="text-align:left;"><span style="font-size:200%;">2</span>Train a model</p>
                <p style="text-align:left;"><span style="font-size:200%;">3</span>Test using test set</p>
                <p style="text-align:left;"><span style="font-size:200%;">4</span>Use in real world</p>
                <p style="text-align:left;"><span style="font-size:200%;">5</span>[Optional] Refine model over time</p>
                </section>
                <section>
                <h2>Today?</h2>
                <p style="text-align:left;">Focus on: feature extraction</p>
                <p style="text-align:left;">Build a Python-based tokenizer</p>
                <p style="text-align:left;"><strong>Token:</strong> the unit we operate on (a single 'word' separated by whitespace)</p>
                </section>
                <section>
                <h2>Probability Notation</h2>
                <p style="text-align:left;">$P(x)$: The probability of random event $x$, range $[0,1]$</p>
                <p style="text-align:left;">$P(x \mid y)$: The probability of random event $x$ given random event $y$</p>
                <p style="text-align:left;">$P(x,y)$: The probability of random events $x$ and $y$</p>
                <p style="text-align:left;">$P(x,y) = P(x) * P(y)$: For independent events $x$ and $y$</p>
                <p style="text-align:left;">$\lvert X \rvert$: The number of elements in <strong>set</strong> $X$</p>
                </section>
                <section>
                <h2>Bayes' Theorem</h2>
                <br />
                $$ P(A \mid B) = \frac{P(B \mid A) * P(A)}{P(B)}$$
                <br />
                <h2>Conditional Independence</h2>
                <br />
                $$ P(A,D \mid B) = P(A \mid B) * P(D \mid B)$$
                </section>
                <section>
                <h2>Bag of Words Model</h2>
                <p style="text-align:left;">Think of all words in the spam or not spam classes as a <strong>giant unordered set</strong> independent from each other within each class.  Learn from all of them at once.</p>
                </section>
                <section>
                <h2>Na&iuml;ve Bayes Classification</h2>
                <br />
                $$P(C \mid F_1, \ldots, F_n)$$
                <br />
                <p style="text-align:left;">For us, we have two $c$ values in $C$: spam and not spam.</p>
                <br />
                $$P(C = \text{spam} \mid F_1 = w_1, \ldots, F_n = w_n)$$
                <br />
                <p style="text-align:left;">and,</p>
                <br />
                $$P(C = \text{not spam} \mid F_1 = w_1, \ldots, F_n = w_n)$$
                <br />
                <p style="text-align:left;">where each $w_i$ is a word occurring in a query document.</p>
                <br />
                </section>
                <section>
                <h2>Apply Bayes' Theorem (spam)</h2>
                <br />
                $$ P(A \mid B) = \frac{P(B \mid A) * P(A)}{P(B)}$$
                <hr>
                <br />
                $$P(C = \text{spam} \mid F_1 = w_1, \ldots, F_n = w_n) = $$
                <br />
                $$\frac{P(F_1 = w_1, \ldots, F_n = w_n \mid \text{spam}) * P(\text{spam})}{P(F_1 = w_1, \ldots, F_n = w_n)}$$
                </section>
                <section>
                <h3>Apply Independence Assumptions (na&iuml;ve)</h3>
                <br />
                $$P(x,y) = P(x) * P(y)$$
                <br />
                $$ P(A,D \mid B) = P(A \mid B) * P(D \mid B)$$ 
                <hr>
                <br />
                $$\frac{P(F_1 = w_1, \ldots, F_n = w_n \mid \text{spam}) * P(\text{spam})}{P(F_1 = w_1, \ldots, F_n = w_n)} = $$
                <br />
                <span style="color:red;">$$\frac{P(F_1 = w_1 \mid \text{spam}) * \cdots * P(F_n = w_n \mid \text{spam}) * P(\text{spam})}{P(F_1 = w_1)  * \cdots * P(F_n = w_n)}$$</span>
                <br />
                </section>
                <section>
                <h2>Cliff's Notes Version</h2>
                <br />
                $$P(C = \text{spam} \mid F_1 = w_1, \ldots, F_n = w_n) = $$
                <br />
                <span style="color:red;">$$\frac{P(F_1 = w_1 \mid \text{spam}) * \cdots * P(F_n = w_n \mid \text{spam}) * P(\text{spam})}{P(F_1 = w_1)  * \cdots * P(F_n = w_n)}$$</span>
                </section>
                <section>
                <h3>Maximum a Posteriori (MAP) Decision Rule</h3>
                <br />
                $$ \text{classify}(f_1,\ldots,f_n) = $$
                <br />
                $$\mathop{\text{argmax}}\limits_c P(C = c) \displaystyle\prod\limits_{i=1}^n P(F_i = f_i \mid C = c)$$
                <br />
                <small>You can <strong>ignore</strong> the denominator as it is equivalent across classes for a given set of $f_i$ tokens.</small>
                </section>
                <section>
                <h2>Approximating Probabilities with Frequencies</h2>
                <br />
                <p style="text-align:left;"><span style="font-size:150%;">1. </span> $P(\text{spam}) = \frac{\lvert \text{spam} \rvert}{\lvert \text{spam} \rvert + \lvert \text{not spam} \rvert}$</p>
                <br />
                <p style="text-align:left;"><span style="font-size:150%;">2. </span> $P(\text{not spam}) = \frac{\lvert \text{not spam} \rvert}{\lvert \text{spam} \rvert + \lvert \text{not spam} \rvert}$</p>
                <br />
                <p style="text-align:left;"><span style="font-size:150%;">3. </span> $P(w_i \mid \text{spam}) = \frac{\lvert w_i \text{ in spam}\rvert}{\lvert \text{spam} \rvert}$</p>
                <br />
                <p style="text-align:left;"><span style="font-size:150%;">4. </span> $P(w_i \mid \text{not spam}) = \frac{\lvert w_i \text{ in not spam} \rvert}{\lvert \text{not spam} \rvert}$</p>
                </section>
                <section>
                <h2>How do we get these values?</h2>
                <h3 style="color:red;" class="fragment">You literally count the words in emails</h3>
                </section>
                <section>
                <h2><strong>So, let's start getting words!</strong></h2>
                </section>
			</div>
		</div>

		<script src="../js/head.min.js"></script>
		<script src="../js/reveal.min.js"></script>
        <script type="text/javascript"
            src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
       </script>
       <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
       </script>

		<script>
			Reveal.initialize({
                rollingLinks: false,
				controls: false,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme,
				transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/fade/none

				dependencies: [
					{ src: '../js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../js/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../js/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../js/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: '../js/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});
		</script>

	</body>
</html>
